{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shunya Problem Statement.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA_QWemG8CR8"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import re\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFFkWbg88GZR"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Dataset/\"\n",
        "image = cv2.imread(\"/content/drive/MyDrive/Dataset/1.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "6Q5b9aQP6dE0",
        "outputId": "025715c9-63bb-4c11-d8c1-8abecd0b4043"
      },
      "source": [
        "def blur_and_threshold(gray):\n",
        "    gray = cv2.GaussianBlur(gray,(3,3),2)\n",
        "    threshold = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "    threshold = cv2.fastNlMeansDenoising(threshold, 11, 31, 9)\n",
        "    return threshold\n",
        "\n",
        "def biggest_contour(contours,min_area):\n",
        "    biggest = None\n",
        "    max_area = 0\n",
        "    biggest_n=0\n",
        "    approx_contour=None\n",
        "    for n,i in enumerate(contours):\n",
        "            area = cv2.contourArea(i)\n",
        "         \n",
        "            if area > min_area/10:\n",
        "                    peri = cv2.arcLength(i,True)\n",
        "                    approx = cv2.approxPolyDP(i,0.02*peri,True)\n",
        "                    if area > max_area and len(approx)==4:\n",
        "                            biggest = approx\n",
        "                            max_area = area\n",
        "                            biggest_n=n\n",
        "                            approx_contour=approx\n",
        "                            \n",
        "                                                   \n",
        "    return biggest_n,approx_contour\n",
        "\n",
        "\n",
        "def order_points(pts):\n",
        " \n",
        "    pts=pts.reshape(4,2)\n",
        "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
        "\n",
        "    s = pts.sum(axis = 1)\n",
        "    rect[0] = pts[np.argmin(s)]\n",
        "    rect[2] = pts[np.argmax(s)]\n",
        "\n",
        "    diff = np.diff(pts, axis = 1)\n",
        "    rect[1] = pts[np.argmin(diff)]\n",
        "    rect[3] = pts[np.argmax(diff)]\n",
        "\n",
        "    return rect\n",
        "\n",
        "def four_point_transform(image, pts):\n",
        "\n",
        "    rect = order_points(pts)\n",
        "    (tl, tr, br, bl) = rect\n",
        "\n",
        "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
        "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
        "    maxWidth = max(int(widthA), int(widthB))\n",
        "   \n",
        "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
        "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
        "    maxHeight = max(int(heightA), int(heightB))\n",
        "\n",
        "    dst = np.array([\n",
        "        [0, 0],\n",
        "        [maxWidth - 1, 0],\n",
        "        [maxWidth - 1, maxHeight - 1],\n",
        "        [0, maxHeight - 1]], dtype = \"float32\")\n",
        "\n",
        "    M = cv2.getPerspectiveTransform(rect, dst)\n",
        "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
        "\n",
        "    return warped\n",
        "\n",
        "def transformation(image):\n",
        "  image=image.copy()  \n",
        "  height, width, channels = image.shape\n",
        "  gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "  image_size=gray.size\n",
        "  \n",
        "  threshold=blur_and_threshold(gray)\n",
        "\n",
        "  edges = cv2.Canny(threshold,50,150,apertureSize = 7)\n",
        "  contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  simplified_contours = []\n",
        "\n",
        "  for cnt in contours:\n",
        "      hull = cv2.convexHull(cnt)\n",
        "      simplified_contours.append(cv2.approxPolyDP(hull,\n",
        "                                0.001*cv2.arcLength(hull,True),True))\n",
        "  simplified_contours = np.array(simplified_contours)\n",
        "  biggest_n,approx_contour = biggest_contour(simplified_contours,image_size)\n",
        "\n",
        "  threshold = cv2.drawContours(image, simplified_contours ,biggest_n, (0,255,0), 1)\n",
        "\n",
        "  dst = 0\n",
        "  if approx_contour is not None and len(approx_contour)==4:\n",
        "      approx_contour=np.float32(approx_contour)\n",
        "      dst=four_point_transform(threshold,approx_contour)\n",
        "  croppedImage = dst\n",
        "  return croppedImage\n",
        "\n",
        "def increase_brightness(img, value=30):\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    h, s, v = cv2.split(hsv)\n",
        "    lim = 255 - value\n",
        "    v[v > lim] = 255\n",
        "    v[v <= lim] += value\n",
        "    final_hsv = cv2.merge((h, s, v))\n",
        "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "    return img  \n",
        "\n",
        "def final_image(rotated):\n",
        "\n",
        "  kernel_sharpening = np.array([[0,-1,0], \n",
        "                                [-1, 5,-1],\n",
        "                                [0,-1,0]])\n",
        "  sharpened = cv2.filter2D(rotated, -1, kernel_sharpening)\n",
        "  sharpened=increase_brightness(sharpened,30)  \n",
        "  return sharpened\n",
        "\n",
        "blurred_threshold = transformation(image)\n",
        "cleaned_image = final_image(blurred_threshold)\n",
        "cv2.imwrite(path + \"Final_Image1.png\", cleaned_image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-dd2111991548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mblurred_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mcleaned_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblurred_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Final_Image1.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleaned_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-dd2111991548>\u001b[0m in \u001b[0;36mfinal_image\u001b[0;34m(rotated)\u001b[0m\n\u001b[1;32m    109\u001b[0m                                 [0,-1,0]])\n\u001b[1;32m    110\u001b[0m   \u001b[0msharpened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_sharpening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m   \u001b[0msharpened\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincrease_brightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharpened\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msharpened\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-dd2111991548>\u001b[0m in \u001b[0;36mincrease_brightness\u001b[0;34m(img, value)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mincrease_brightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mhsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mlim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<3>; VDepth = cv::impl::{anonymous}::Set<0, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = (cv::impl::<unnamed>::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdyta1BY8Kxc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}